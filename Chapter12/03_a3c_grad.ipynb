{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import gymnasium as gym\n",
    "import ptan\n",
    "from ptan.experience import VectorExperienceSourceFirstLast\n",
    "from ptan.common.utils import TBMeanTracker\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae254a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils as nn_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b09038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "ENTROPY_BETA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_STEPS = 4\n",
    "CLIP_GRAD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSES_COUNT = 4\n",
    "NUM_ENVS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f1c76",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "GRAD_BATCH = 64\n",
    "TRAIN_BATCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b41d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "NAME = 'pong'\n",
    "REWARD_BOUND = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env() -> gym.Env:\n",
    "    return ptan.common.wrappers.wrap_dqn(gym.make(\"PongNoFrameskip-v4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads_func(proc_name: str, net: common.AtariA2C, device: torch.device,\n",
    "               train_queue: mp.Queue):\n",
    "    env_factories = [make_env for _ in range(NUM_ENVS)]\n",
    "    env = gym.vector.SyncVectorEnv(env_factories)\n",
    "\n",
    "    agent = ptan.agent.PolicyAgent(lambda x: net(x)[0], device=device, apply_softmax=True)\n",
    "    exp_source = VectorExperienceSourceFirstLast(\n",
    "        env, agent, gamma=GAMMA, steps_count=REWARD_STEPS)\n",
    "\n",
    "    batch = []\n",
    "    frame_idx = 0\n",
    "    writer = SummaryWriter(comment=proc_name)\n",
    "\n",
    "    with common.RewardTracker(writer, REWARD_BOUND) as tracker:\n",
    "        with TBMeanTracker(writer, 100) as tb_tracker:\n",
    "            for exp in exp_source:\n",
    "                frame_idx += 1\n",
    "                new_rewards = exp_source.pop_total_rewards()\n",
    "                if new_rewards and tracker.reward(new_rewards[0], frame_idx):\n",
    "                    break\n",
    "\n",
    "                batch.append(exp)\n",
    "                if len(batch) < GRAD_BATCH:\n",
    "                    continue\n",
    "\n",
    "                data = common.unpack_batch(batch, net, device=device, gamma=GAMMA,\n",
    "                                           reward_steps=REWARD_STEPS)\n",
    "                states_v, actions_t, vals_ref_v = data\n",
    "                batch.clear()\n",
    "\n",
    "                net.zero_grad()\n",
    "                logits_v, value_v = net(states_v)\n",
    "                loss_value_v = F.mse_loss(value_v.squeeze(-1), vals_ref_v)\n",
    "\n",
    "                log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "                adv_v = vals_ref_v - value_v.detach()\n",
    "                log_p_a = log_prob_v[range(GRAD_BATCH), actions_t]\n",
    "                log_prob_actions_v = adv_v * log_p_a\n",
    "                loss_policy_v = -log_prob_actions_v.mean()\n",
    "\n",
    "                prob_v = F.softmax(logits_v, dim=1)\n",
    "                ent = (prob_v * log_prob_v).sum(dim=1).mean()\n",
    "                entropy_loss_v = ENTROPY_BETA * ent\n",
    "\n",
    "                loss_v = entropy_loss_v + loss_value_v + loss_policy_v\n",
    "                loss_v.backward()\n",
    "\n",
    "                tb_tracker.track(\"advantage\", adv_v, frame_idx)\n",
    "                tb_tracker.track(\"values\", value_v, frame_idx)\n",
    "                tb_tracker.track(\"batch_rewards\", vals_ref_v, frame_idx)\n",
    "                tb_tracker.track(\"loss_entropy\", entropy_loss_v, frame_idx)\n",
    "                tb_tracker.track(\"loss_policy\", loss_policy_v, frame_idx)\n",
    "                tb_tracker.track(\"loss_value\", loss_value_v, frame_idx)\n",
    "                tb_tracker.track(\"loss_total\", loss_v, frame_idx)\n",
    "\n",
    "                # gather gradients\n",
    "                nn_utils.clip_grad_norm_(\n",
    "                    net.parameters(), CLIP_GRAD)\n",
    "                grads = [\n",
    "                    param.grad.data.cpu().numpy() if param.grad is not None else None\n",
    "                    for param in net.parameters()\n",
    "                ]\n",
    "                train_queue.put(grads)\n",
    "\n",
    "    train_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method('spawn')\n",
    "    os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dev\", default=\"cpu\", help=\"Device to use, default=cpu\")\n",
    "    parser.add_argument(\"-n\", \"--name\", required=True, help=\"Name of the run\")\n",
    "    args = parser.parse_args()\n",
    "    device = torch.device(args.dev)\n",
    "\n",
    "    env = make_env()\n",
    "    net = common.AtariA2C(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    net.share_memory()\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)\n",
    "\n",
    "    train_queue = mp.Queue(maxsize=PROCESSES_COUNT)\n",
    "    data_proc_list = []\n",
    "    for proc_idx in range(PROCESSES_COUNT):\n",
    "        proc_name = f\"-a3c-grad_pong_{args.name}#{proc_idx}\"\n",
    "        p_args = (proc_name, net, device, train_queue)\n",
    "        data_proc = mp.Process(target=grads_func, args=p_args)\n",
    "        data_proc.start()\n",
    "        data_proc_list.append(data_proc)\n",
    "\n",
    "    batch = []\n",
    "    step_idx = 0\n",
    "    grad_buffer = None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            train_entry = train_queue.get()\n",
    "            if train_entry is None:\n",
    "                break\n",
    "\n",
    "            step_idx += 1\n",
    "\n",
    "            if grad_buffer is None:\n",
    "                grad_buffer = train_entry\n",
    "            else:\n",
    "                for tgt_grad, grad in zip(grad_buffer, train_entry):\n",
    "                    tgt_grad += grad\n",
    "\n",
    "            if step_idx % TRAIN_BATCH == 0:\n",
    "                for param, grad in zip(net.parameters(), grad_buffer):\n",
    "                    param.grad = torch.FloatTensor(grad).to(device)\n",
    "\n",
    "                nn_utils.clip_grad_norm_(net.parameters(), CLIP_GRAD)\n",
    "                optimizer.step()\n",
    "                grad_buffer = None\n",
    "    finally:\n",
    "        for p in data_proc_list:\n",
    "            p.terminate()\n",
    "            p.join()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
