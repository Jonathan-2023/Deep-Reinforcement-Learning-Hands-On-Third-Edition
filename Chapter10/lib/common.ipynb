{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a01dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptan\n",
    "import ptan.ignite as ptan_ignite\n",
    "from ignite.engine import Engine\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calc_values_of_states(states, net, device=\"cpu\"):\n",
    "    mean_vals = []\n",
    "    for batch in np.array_split(states, 64):\n",
    "        states_v = torch.tensor(batch).to(device)\n",
    "        action_values_v = net(states_v)\n",
    "        best_action_values_v = action_values_v.max(1)[0]\n",
    "        mean_vals.append(best_action_values_v.mean().item())\n",
    "    return np.mean(mean_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch(batch):\n",
    "    states, actions, rewards, dones, last_states = [], [], [], [], []\n",
    "    for exp in batch:\n",
    "        state = np.asarray(exp.state)\n",
    "        states.append(state)\n",
    "        actions.append(exp.action)\n",
    "        rewards.append(exp.reward)\n",
    "        dones.append(exp.last_state is None)\n",
    "        if exp.last_state is None:\n",
    "            last_states.append(state)       # the result will be masked anyway\n",
    "        else:\n",
    "            last_states.append(np.asarray(exp.last_state))\n",
    "    return np.asarray(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "           np.array(dones, dtype=np.uint8), np.asarray(last_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch, net, tgt_net, gamma, device=\"cpu\"):\n",
    "    states, actions, rewards, dones, next_states = unpack_batch(batch)\n",
    "\n",
    "    states_v = torch.tensor(states).to(device)\n",
    "    next_states_v = torch.tensor(next_states).to(device)\n",
    "    actions_v = torch.tensor(actions).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    done_mask = torch.BoolTensor(dones).to(device)\n",
    "\n",
    "    state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
    "    next_state_actions = net(next_states_v).max(1)[1]\n",
    "    next_state_values = tgt_net(next_states_v).gather(1, next_state_actions.unsqueeze(-1)).squeeze(-1)\n",
    "    next_state_values[done_mask] = 0.0\n",
    "\n",
    "    expected_state_action_values = next_state_values.detach() * gamma + rewards_v\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(buffer: ptan.experience.ExperienceReplayBuffer,\n",
    "                    initial: int, batch_size: int):\n",
    "    buffer.populate(initial)\n",
    "    while True:\n",
    "        buffer.populate(1)\n",
    "        yield buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ignite(engine: Engine, exp_source, run_name: str,\n",
    "                 extra_metrics: Iterable[str] = ()):\n",
    "    # get rid of missing metrics warning\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "    handler = ptan_ignite.EndOfEpisodeHandler(exp_source, subsample_end_of_episode=100)\n",
    "    handler.attach(engine)\n",
    "    ptan_ignite.EpisodeFPSHandler().attach(engine)\n",
    "\n",
    "    @engine.on(ptan_ignite.EpisodeEvents.EPISODE_COMPLETED)\n",
    "    def episode_completed(trainer: Engine):\n",
    "        passed = trainer.state.metrics.get('time_passed', 0)\n",
    "        print(\"Episode %d: reward=%.0f, steps=%s, \"\n",
    "              \"speed=%.1f f/s, elapsed=%s\" % (\n",
    "            trainer.state.episode, trainer.state.episode_reward,\n",
    "            trainer.state.episode_steps,\n",
    "            trainer.state.metrics.get('avg_fps', 0),\n",
    "            timedelta(seconds=int(passed))))\n",
    "\n",
    "    now = datetime.now().isoformat(timespec='minutes')\n",
    "    logdir = f\"runs/{now}-{run_name}\"\n",
    "    tb = tb_logger.TensorboardLogger(log_dir=logdir)\n",
    "    run_avg = RunningAverage(output_transform=lambda v: v['loss'])\n",
    "    run_avg.attach(engine, \"avg_loss\")\n",
    "\n",
    "    metrics = ['reward', 'steps', 'avg_reward']\n",
    "    handler = tb_logger.OutputHandler(\n",
    "        tag=\"episodes\", metric_names=metrics)\n",
    "    event = ptan_ignite.EpisodeEvents.EPISODE_COMPLETED\n",
    "    tb.attach(engine, log_handler=handler, event_name=event)\n",
    "\n",
    "    ptan_ignite.PeriodicEvents().attach(engine)\n",
    "    metrics = ['avg_loss', 'avg_fps']\n",
    "    metrics.extend(extra_metrics)\n",
    "    handler = tb_logger.OutputHandler(\n",
    "        tag=\"train\", metric_names=metrics,\n",
    "        output_transform=lambda a: a)\n",
    "    event = ptan_ignite.PeriodEvents.ITERS_1000_COMPLETED\n",
    "    tb.attach(engine, log_handler=handler, event_name=event)\n",
    "    return tb"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
