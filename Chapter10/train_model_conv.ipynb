{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptan\n",
    "import pathlib\n",
    "import argparse\n",
    "from gymnasium import wrappers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf983015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import environ, data, models, common, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVES_DIR = pathlib.Path(\"saves\")\n",
    "STOCKS = \"data/YNDX_160101_161231.csv\"\n",
    "VAL_STOCKS = \"data/YNDX_150101_151231.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78360bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BARS_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_START = 1.0\n",
    "EPS_FINAL = 0.1\n",
    "EPS_STEPS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d949278",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a62be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "REPLAY_SIZE = 100000\n",
    "REPLAY_INITIAL = 10000\n",
    "REWARD_STEPS = 2\n",
    "LEARNING_RATE = 0.0001\n",
    "STATES_TO_EVALUATE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dev\", help=\"Training device name\", default=\"cpu\")\n",
    "    parser.add_argument(\"--data\", default=STOCKS, help=f\"Stocks file or dir, default={STOCKS}\")\n",
    "    parser.add_argument(\"--year\", type=int, help=\"Year to train on, overrides --data\")\n",
    "    parser.add_argument(\"--val\", default=VAL_STOCKS, help=\"Validation data, default=\" + VAL_STOCKS)\n",
    "    parser.add_argument(\"-r\", \"--run\", required=True, help=\"Run name\")\n",
    "    args = parser.parse_args()\n",
    "    device = torch.device(args.dev)\n",
    "\n",
    "    saves_path = SAVES_DIR / f\"conv-{args.run}\"\n",
    "    saves_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data_path = pathlib.Path(args.data)\n",
    "    val_path = pathlib.Path(args.val)\n",
    "\n",
    "    if args.year is not None or data_path.is_file():\n",
    "        if args.year is not None:\n",
    "            stock_data = data.load_year_data(args.year)\n",
    "        else:\n",
    "            stock_data = {\"YNDX\": data.load_relative(data_path)}\n",
    "        env = environ.StocksEnv(stock_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "        env_tst = environ.StocksEnv(stock_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "    elif data_path.is_dir():\n",
    "        env = environ.StocksEnv.from_dir(data_path, bars_count=BARS_COUNT, state_1d=True)\n",
    "        env_tst = environ.StocksEnv.from_dir(data_path, bars_count=BARS_COUNT, state_1d=True)\n",
    "    else:\n",
    "        raise RuntimeError(\"No data to train on\")\n",
    "\n",
    "    env = wrappers.TimeLimit(env, max_episode_steps=1000)\n",
    "    val_data = {\"YNDX\": data.load_relative(val_path)}\n",
    "    env_val = environ.StocksEnv(val_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "\n",
    "    net = models.DQNConv1D(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(EPS_START)\n",
    "    eps_tracker = ptan.actions.EpsilonTracker(\n",
    "        selector, EPS_START, EPS_FINAL, EPS_STEPS)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "        env, agent, GAMMA, steps_count=REWARD_STEPS)\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "        exp_source, REPLAY_SIZE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    def process_batch(engine, batch):\n",
    "        optimizer.zero_grad()\n",
    "        loss_v = common.calc_loss(\n",
    "            batch, net, tgt_net.target_model,\n",
    "            gamma=GAMMA ** REWARD_STEPS, device=device)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        eps_tracker.frame(engine.state.iteration)\n",
    "\n",
    "        if getattr(engine.state, \"eval_states\", None) is None:\n",
    "            eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
    "            eval_states = [np.asarray(transition.state)\n",
    "                           for transition in eval_states]\n",
    "            engine.state.eval_states = np.asarray(eval_states)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss_v.item(),\n",
    "            \"epsilon\": selector.epsilon,\n",
    "        }\n",
    "\n",
    "    engine = Engine(process_batch)\n",
    "    tb = common.setup_ignite(engine, exp_source, f\"conv-{args.run}\",\n",
    "                             extra_metrics=('values_mean',))\n",
    "\n",
    "    @engine.on(ptan.ignite.PeriodEvents.ITERS_1000_COMPLETED)\n",
    "    def sync_eval(engine: Engine):\n",
    "        tgt_net.sync()\n",
    "\n",
    "        mean_val = common.calc_values_of_states(\n",
    "            engine.state.eval_states, net, device=device)\n",
    "        engine.state.metrics[\"values_mean\"] = mean_val\n",
    "        if getattr(engine.state, \"best_mean_val\", None) is None:\n",
    "            engine.state.best_mean_val = mean_val\n",
    "        if engine.state.best_mean_val < mean_val:\n",
    "            print(\"%d: Best mean value updated %.3f -> %.3f\" % (\n",
    "                engine.state.iteration, engine.state.best_mean_val,\n",
    "                mean_val))\n",
    "            path = saves_path / (\"mean_value-%.3f.data\" % mean_val)\n",
    "            torch.save(net.state_dict(), path)\n",
    "            engine.state.best_mean_val = mean_val\n",
    "\n",
    "    @engine.on(ptan.ignite.PeriodEvents.ITERS_10000_COMPLETED)\n",
    "    def validate(engine: Engine):\n",
    "        res = validation.validation_run(env_tst, net, device=device)\n",
    "        print(\"%d: tst: %s\" % (engine.state.iteration, res))\n",
    "        for key, val in res.items():\n",
    "            engine.state.metrics[key + \"_tst\"] = val\n",
    "        res = validation.validation_run(env_val, net, device=device)\n",
    "        print(\"%d: val: %s\" % (engine.state.iteration, res))\n",
    "        for key, val in res.items():\n",
    "            engine.state.metrics[key + \"_val\"] = val\n",
    "        val_reward = res['episode_reward']\n",
    "        if getattr(engine.state, \"best_val_reward\", None) is None:\n",
    "            engine.state.best_val_reward = val_reward\n",
    "        if engine.state.best_val_reward < val_reward:\n",
    "            print(\"Best validation reward updated: %.3f -> %.3f, model saved\" % (\n",
    "                engine.state.best_val_reward, val_reward\n",
    "            ))\n",
    "            engine.state.best_val_reward = val_reward\n",
    "            path = saves_path / (\"val_reward-%.3f.data\" % val_reward)\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "\n",
    "    event = ptan.ignite.PeriodEvents.ITERS_10000_COMPLETED\n",
    "    tst_metrics = [m + \"_tst\" for m in validation.METRICS]\n",
    "    tst_handler = tb_logger.OutputHandler(\n",
    "        tag=\"test\", metric_names=tst_metrics)\n",
    "    tb.attach(engine, log_handler=tst_handler, event_name=event)\n",
    "\n",
    "    val_metrics = [m + \"_val\" for m in validation.METRICS]\n",
    "    val_handler = tb_logger.OutputHandler(\n",
    "        tag=\"validation\", metric_names=val_metrics)\n",
    "    tb.attach(engine, log_handler=val_handler, event_name=event)\n",
    "\n",
    "    engine.run(common.batch_generator(buffer, REPLAY_INITIAL, BATCH_SIZE))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
