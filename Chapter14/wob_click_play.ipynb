{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3178de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989c69e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from lib import wob, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f61f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'miniwob/click-dialog-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-m\", \"--model\", help=\"Model file to load\")\n",
    "    parser.add_argument(\"--count\", type=int, default=1, help=\"Count of episodes to play, default=1\")\n",
    "    parser.add_argument(\"--env\", default=ENV_NAME, help=\"Environment name to solve, default=\" + ENV_NAME)\n",
    "    parser.add_argument(\"--verbose\", default=False, action='store_true', help=\"Display every step\")\n",
    "    parser.add_argument(\"--render\", default=False, action='store_true', help=\"Show browser window\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    env_name = args.env\n",
    "    if not env_name.startswith('miniwob/'):\n",
    "        env_name = \"miniwob/\" + env_name\n",
    "\n",
    "    render_mode = 'human' if args.render else None\n",
    "    env = wob.MiniWoBClickWrapper.create(env_name, render_mode=render_mode)\n",
    "\n",
    "    net = model.Model(input_shape=wob.WOB_SHAPE, n_actions=env.action_space.n)\n",
    "    if args.model:\n",
    "        net.load_state_dict(torch.load(args.model, map_location=torch.device('cpu'), weights_only=True))\n",
    "\n",
    "    steps_count = 0\n",
    "    reward_sum = 0\n",
    "\n",
    "    for round_idx in range(args.count):\n",
    "        step_idx = 0\n",
    "        obs, info = env.reset()\n",
    "        while True:\n",
    "            obs_v = torch.tensor(np.expand_dims(obs, axis=0))\n",
    "            logits_v = net(obs_v)[0]\n",
    "            policy = F.softmax(logits_v, dim=1).data.numpy()[0]\n",
    "            action = np.random.choice(len(policy), p=policy)\n",
    "\n",
    "            obs, reward, done, is_tr, info = env.step(action)\n",
    "            if args.verbose:\n",
    "                print(step_idx, reward, done, info)\n",
    "\n",
    "            step_idx += 1\n",
    "            reward_sum += reward\n",
    "            steps_count += 1\n",
    "            if done:\n",
    "                print(\"Round %d done\" % round_idx)\n",
    "                break\n",
    "    print(\"Done %d rounds, mean steps %.2f, mean reward %.3f\" % (\n",
    "        args.count, steps_count / args.count, reward_sum / args.count\n",
    "    ))\n",
    "\n",
    "    if args.render:\n",
    "        input(\"Press enter to close the browser >>> \")\n",
    "        env.close()\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
