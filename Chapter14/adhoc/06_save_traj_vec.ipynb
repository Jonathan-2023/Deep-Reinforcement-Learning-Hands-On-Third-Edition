{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool saves trajectories from several games using the given model, vectorized version\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "import pathlib\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import model, wob, demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6aad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'miniwob/count-sides-v1'\n",
    "N_ENVS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-m\", \"--model\", required=True, help=\"Model file\")\n",
    "    parser.add_argument(\"-o\", \"--output\", required=True, help=\"Dir to save screenshots\")\n",
    "    parser.add_argument(\"-a\", type=int, help=\"If given, this action will be executed\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    envs = [\n",
    "        lambda: wob.MiniWoBClickWrapper.create(ENV_NAME)\n",
    "        for _ in range(N_ENVS)\n",
    "    ]\n",
    "    env = gym.vector.AsyncVectorEnv(envs)\n",
    "\n",
    "    net = model.Model(input_shape=wob.WOB_SHAPE, n_actions=env.single_action_space.n)\n",
    "    net.load_state_dict(torch.load(args.model, map_location=torch.device('cpu'), weights_only=True))\n",
    "    out_dir = pathlib.Path(args.output)\n",
    "    for i in range(N_ENVS):\n",
    "        (out_dir / str(i)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    step_idx = 0\n",
    "    done_envs = set()\n",
    "\n",
    "    while len(done_envs) < N_ENVS:\n",
    "        obs_v = torch.tensor(obs)\n",
    "        logits_v = net(obs_v)[0]\n",
    "        policy = F.softmax(logits_v, dim=1).data.numpy()\n",
    "        actions = [\n",
    "            np.random.choice(len(policy[i]), p=policy[i]) if args.a is None else args.a\n",
    "            for i in range(N_ENVS)\n",
    "        ]\n",
    "\n",
    "        new_obs, rewards, dones, is_trs, infos = env.step(actions)\n",
    "        for i, (action, reward, done, is_tr) in enumerate(zip(actions, rewards, dones, is_trs)):\n",
    "            b_x, b_y = wob.action_to_bins(action)\n",
    "            print(f\"{step_idx}-{i}: act={action}, b={b_x}_{b_y}, r={reward}, done={done}, tr={is_tr}\")\n",
    "            p = out_dir / str(i) / f\"scr_{step_idx:03d}_act={action}_b={b_x}-{b_y}_r={reward:.2f}_d={done:d}_tr={is_tr:d}.png\"\n",
    "            demos.save_obs_image(obs[i], action, str(p))\n",
    "            if is_tr or done:\n",
    "                done_envs.add(i)\n",
    "        obs = new_obs\n",
    "        step_idx += 1\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
