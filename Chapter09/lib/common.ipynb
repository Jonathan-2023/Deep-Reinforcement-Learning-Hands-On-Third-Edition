{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bed6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dataclasses\n",
    "import typing as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptan.actions import EpsilonGreedyActionSelector\n",
    "from ptan.experience import ExperienceFirstLast, \\\n",
    "    ExperienceReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18645d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Hyperparams:\n",
    "    env_name: str\n",
    "    stop_reward: float\n",
    "    run_name: str\n",
    "    replay_size: int\n",
    "    replay_initial: int\n",
    "    target_net_sync: int\n",
    "    epsilon_frames: int\n",
    "\n",
    "    learning_rate: float = 0.0001\n",
    "    batch_size: int = 32\n",
    "    gamma: float = 0.99\n",
    "    epsilon_start: float = 1.0\n",
    "    epsilon_final: float = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_PARAMS = {\n",
    "    'pong': Hyperparams(\n",
    "        env_name=\"PongNoFrameskip-v4\",\n",
    "        stop_reward=18.0,\n",
    "        run_name=\"pong\",\n",
    "        replay_size=100_000,\n",
    "        replay_initial=10_000,\n",
    "        target_net_sync=1000,\n",
    "        epsilon_frames=100_000,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9062a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch(batch: tt.List[ExperienceFirstLast]):\n",
    "    states, actions, rewards, dones, last_states = [],[],[],[],[]\n",
    "    for exp in batch:\n",
    "        states.append(exp.state)\n",
    "        actions.append(exp.action)\n",
    "        rewards.append(exp.reward)\n",
    "        dones.append(exp.last_state is None)\n",
    "        if exp.last_state is None:\n",
    "            lstate = exp.state  # the result will be masked anyway\n",
    "        else:\n",
    "            lstate = exp.last_state\n",
    "        last_states.append(lstate)\n",
    "    return np.asarray(states), \\\n",
    "        np.array(actions), \\\n",
    "        np.array(rewards, dtype=np.float32), \\\n",
    "        np.array(dones, dtype=bool), \\\n",
    "        np.asarray(last_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77936a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_dqn(\n",
    "        batch: tt.List[ExperienceFirstLast],\n",
    "        net: nn.Module, tgt_net: nn.Module,\n",
    "        gamma: float, device: torch.device) -> torch.Tensor:\n",
    "    states, actions, rewards, dones, next_states = \\\n",
    "        unpack_batch(batch)\n",
    "\n",
    "    states_v = torch.as_tensor(states).to(device)\n",
    "    next_states_v = torch.as_tensor(next_states).to(device)\n",
    "    actions_v = torch.LongTensor(actions).to(device)\n",
    "    rewards_v = torch.FloatTensor(rewards).to(device)\n",
    "    done_mask = torch.BoolTensor(dones).to(device)\n",
    "\n",
    "    actions_v = actions_v.unsqueeze(-1)\n",
    "    state_action_vals = net(states_v).gather(1, actions_v)\n",
    "    state_action_vals = state_action_vals.squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        next_state_vals = tgt_net(next_states_v).max(1)[0]\n",
    "        next_state_vals[done_mask] = 0.0\n",
    "\n",
    "    bellman_vals = next_state_vals.detach() * gamma + rewards_v\n",
    "    return nn.MSELoss()(state_action_vals, bellman_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonTracker:\n",
    "    def __init__(self, selector: EpsilonGreedyActionSelector,\n",
    "                 params: Hyperparams):\n",
    "        self.selector = selector\n",
    "        self.params = params\n",
    "        self.frame(0)\n",
    "\n",
    "    def frame(self, frame_idx: int):\n",
    "        eps = self.params.epsilon_start - \\\n",
    "              frame_idx / self.params.epsilon_frames\n",
    "        self.selector.epsilon = max(self.params.epsilon_final, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0f3a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def batch_generator(buffer: ExperienceReplayBuffer,\n",
    "                    initial: int, batch_size: int) -> \\\n",
    "        tt.Generator[tt.List[ExperienceFirstLast], None, None]:\n",
    "    buffer.populate(initial)\n",
    "    while True:\n",
    "        buffer.populate(1)\n",
    "        yield buffer.sample(batch_size)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
