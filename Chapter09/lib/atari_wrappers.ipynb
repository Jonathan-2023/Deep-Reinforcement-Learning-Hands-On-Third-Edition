{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptan.common.wrappers import ImageToPyTorch, BufferWrapper\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    StickyActionEnv, NoopResetEnv, EpisodicLifeEnv,\n",
    "    FireResetEnv, WarpFrame, ClipRewardEnv\n",
    ")\n",
    "from stable_baselines3.common.type_aliases import AtariStepReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JustSkipEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n",
    "    \"\"\"\n",
    "    Return only every ``skip``-th frame (frameskipping)\n",
    "\n",
    "    :param env: Environment to wrap\n",
    "    :param skip: Number of ``skip``-th frame\n",
    "        The same action will be taken ``skip`` times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: gym.Env, skip: int = 4) -> None:\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action: int) -> AtariStepReturn:\n",
    "        \"\"\"\n",
    "        Step the environment with the given action\n",
    "        Repeat action, sum reward, and max over last observations.\n",
    "\n",
    "        :param action: the action\n",
    "        :return: observation, reward, terminated, truncated, information\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        info = {}\n",
    "        obs = None\n",
    "        terminated = truncated = False\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += float(reward)\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariWrapper(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        noop_max: int = 30,\n",
    "        frame_skip: int = 4,\n",
    "        screen_size: int = 84,\n",
    "        terminal_on_life_loss: bool = True,\n",
    "        clip_reward: bool = True,\n",
    "        action_repeat_probability: float = 0.0,\n",
    "    ) -> None:\n",
    "        if action_repeat_probability > 0.0:\n",
    "            env = StickyActionEnv(env, action_repeat_probability)\n",
    "        if noop_max > 0:\n",
    "            env = NoopResetEnv(env, noop_max=noop_max)\n",
    "        # frame_skip=1 is the same as no frame-skip (action repeat)\n",
    "        if frame_skip > 1:\n",
    "            env = JustSkipEnv(env, skip=frame_skip)\n",
    "        if terminal_on_life_loss:\n",
    "            env = EpisodicLifeEnv(env)\n",
    "        if \"FIRE\" in env.unwrapped.get_action_meanings():  # type: ignore[attr-defined]\n",
    "            env = FireResetEnv(env)\n",
    "        env = WarpFrame(env, width=screen_size, height=screen_size)\n",
    "        if clip_reward:\n",
    "            env = ClipRewardEnv(env)\n",
    "\n",
    "        super().__init__(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e592c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_dqn(env: gym.Env, stack_frames: int = 4,\n",
    "             episodic_life: bool = True, clip_reward: bool = True,\n",
    "             noop_max: int = 0) -> gym.Env:\n",
    "    \"\"\"\n",
    "    Apply a common set of wrappers for Atari games.\n",
    "    :param env: Environment to wrap\n",
    "    :param stack_frames: count of frames to stack, default=4\n",
    "    :param episodic_life: convert life to end of episode\n",
    "    :param clip_reward: reward clipping\n",
    "    :param noop_max: how many NOOP actions to execute\n",
    "    :return: wrapped environment\n",
    "    \"\"\"\n",
    "    assert 'NoFrameskip' in env.spec.id\n",
    "    env = AtariWrapper(\n",
    "        env, clip_reward=clip_reward, noop_max=noop_max,\n",
    "        terminal_on_life_loss=episodic_life\n",
    "    )\n",
    "    env = ImageToPyTorch(env)\n",
    "    if stack_frames > 1:\n",
    "        env = BufferWrapper(env, stack_frames)\n",
    "    return env"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
