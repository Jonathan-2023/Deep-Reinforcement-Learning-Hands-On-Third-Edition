{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import ptan.ignite as ptan_ignite\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640aff04",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from lib import dqn_model, common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d21fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"02_env_steps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b627829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(buffer: ptan.experience.ExperienceReplayBuffer,\n",
    "                    initial: int, batch_size: int, steps: int):\n",
    "    buffer.populate(initial)\n",
    "    while True:\n",
    "        buffer.populate(steps)\n",
    "        yield buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ef347",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    random.seed(common.SEED)\n",
    "    torch.manual_seed(common.SEED)\n",
    "    params = common.HYPERPARAMS['pong']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cuda\", default=False, action=\"store_true\", help=\"Enable cuda\")\n",
    "    parser.add_argument(\"--steps\", type=int, default=2, help=\"Amount of steps to do\")\n",
    "    args = parser.parse_args()\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "    env = gym.make(params.env_name)\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "    env.seed(common.SEED)\n",
    "\n",
    "    params.batch_size *= args.steps\n",
    "    net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "    epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "        env, agent, gamma=params.gamma, steps_count=1)\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "        exp_source, buffer_size=params.replay_size)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=params.learning_rate)\n",
    "\n",
    "    def process_batch(engine, batch):\n",
    "        optimizer.zero_grad()\n",
    "        loss_v = common.calc_loss_dqn(batch, net, tgt_net.target_model,\n",
    "                                      gamma=params.gamma, device=device)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        epsilon_tracker.frame(engine.state.iteration * args.steps)\n",
    "        if engine.state.iteration % params.target_net_sync == 0:\n",
    "            tgt_net.sync()\n",
    "        return {\n",
    "            \"loss\": loss_v.item(),\n",
    "            \"epsilon\": selector.epsilon,\n",
    "        }\n",
    "\n",
    "    engine = Engine(process_batch)\n",
    "    ptan_ignite.EndOfEpisodeHandler(exp_source, bound_avg_reward=17.0).attach(engine)\n",
    "    ptan_ignite.EpisodeFPSHandler(fps_mul=args.steps).attach(engine)\n",
    "\n",
    "    @engine.on(ptan_ignite.EndOfEpisodeHandler.Events.EPISODE_COMPLETED)\n",
    "    def episode_completed(trainer: Engine):\n",
    "        print(\"Episode %d: reward=%s, steps=%s, speed=%.3f frames/s, elapsed=%s\" % (\n",
    "            trainer.state.episode, trainer.state.episode_reward,\n",
    "            trainer.state.episode_steps, trainer.state.metrics.get('fps', 0),\n",
    "            timedelta(seconds=trainer.state.metrics.get('time_passed', 0))))\n",
    "\n",
    "    @engine.on(ptan_ignite.EndOfEpisodeHandler.Events.BOUND_REWARD_REACHED)\n",
    "    def game_solved(trainer: Engine):\n",
    "        print(\"Game solved in %s, after %d episodes and %d iterations!\" % (\n",
    "            timedelta(seconds=trainer.state.metrics['time_passed']),\n",
    "            trainer.state.episode, trainer.state.iteration))\n",
    "        trainer.should_terminate = True\n",
    "\n",
    "    logdir = f\"runs/{datetime.now().isoformat(timespec='minutes')}-{params.run_name}-{NAME}={args.steps}\"\n",
    "    tb = tb_logger.TensorboardLogger(log_dir=logdir)\n",
    "    RunningAverage(output_transform=lambda v: v['loss']).attach(engine, \"avg_loss\")\n",
    "\n",
    "    episode_handler = tb_logger.OutputHandler(tag=\"episodes\", metric_names=['reward', 'steps', 'avg_reward'])\n",
    "    tb.attach(engine, log_handler=episode_handler, event_name=ptan_ignite.EndOfEpisodeHandler.Events.EPISODE_COMPLETED)\n",
    "\n",
    "    # write to tensorboard every 100 iterations\n",
    "    ptan_ignite.PeriodicEvents().attach(engine)\n",
    "    handler = tb_logger.OutputHandler(tag=\"train\", metric_names=['avg_loss', 'fps'],\n",
    "                                      output_transform=lambda a: a)\n",
    "    tb.attach(engine, log_handler=handler, event_name=ptan_ignite.PeriodicEvents.Events.ITERATIONS_100_COMPLETED)\n",
    "\n",
    "    engine.run(batch_generator(buffer, params.replay_initial, params.batch_size, args.steps))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
