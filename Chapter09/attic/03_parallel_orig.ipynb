{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e53d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import dqn_model, common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_func(params, net, cuda, exp_queue):\n",
    "    env = gym.make(params.env_name)\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "    writer = SummaryWriter(comment=\"-\" + params.run_name + \"-03_parallel\")\n",
    "\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "    epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=params.gamma, steps_count=1)\n",
    "    exp_source_iter = iter(exp_source)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    with common.RewardTracker(writer, params.stop_reward) as reward_tracker:\n",
    "        while True:\n",
    "            frame_idx += 1\n",
    "            exp = next(exp_source_iter)\n",
    "            exp_queue.put(exp)\n",
    "\n",
    "            epsilon_tracker.frame(frame_idx)\n",
    "\n",
    "            new_rewards = exp_source.pop_total_rewards()\n",
    "            if new_rewards:\n",
    "                if reward_tracker.reward(new_rewards[0], frame_idx, selector.epsilon):\n",
    "                    break\n",
    "\n",
    "    exp_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6182e2b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method('spawn')\n",
    "    params = common.HYPERPARAMS['pong']\n",
    "    params.batch_size *= PLAY_STEPS\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cuda\", default=False, action=\"store_true\", help=\"Enable cuda\")\n",
    "    args = parser.parse_args()\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "    env = gym.make(params.env_name)\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "\n",
    "    net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(experience_source=None, buffer_size=params.replay_size)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=params.learning_rate)\n",
    "\n",
    "    exp_queue = mp.Queue(maxsize=PLAY_STEPS * 2)\n",
    "    play_proc = mp.Process(target=play_func, args=(params, net, args.cuda, exp_queue))\n",
    "    play_proc.start()\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while play_proc.is_alive():\n",
    "#        frame_idx += PLAY_STEPS\n",
    "        #for _ in range(PLAY_STEPS):\n",
    "        while exp_queue.qsize() > 1:\n",
    "            exp = exp_queue.get()\n",
    "            if exp is None:\n",
    "                play_proc.join()\n",
    "                break\n",
    "            buffer._add(exp)\n",
    "            frame_idx += 1\n",
    "            if frame_idx % params.target_net_sync == 0:\n",
    "                tgt_net.sync()\n",
    "\n",
    "        if len(buffer) < params.replay_initial:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        batch = buffer.sample(params.batch_size)\n",
    "        loss_v = common.calc_loss_dqn(batch, net, tgt_net.target_model, gamma=params.gamma, device=device)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
