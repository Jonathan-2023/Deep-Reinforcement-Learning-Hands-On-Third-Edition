{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import collections\n",
    "from dataclasses import dataclass\n",
    "import typing as tt\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import queue\n",
    "from torch import nn\n",
    "from gymnasium.core import WrapperObsType, WrapperActType, SupportsFloat\n",
    "import pathlib\n",
    "from copy import deepcopy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca0a0a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "log = logging.getLogger(\"rlhf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87216909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many transitions to store in episode\n",
    "EPISODE_STEPS = 50\n",
    "# probability to start episode recording\n",
    "START_PROB = 0.00005\n",
    "LABELS_FILE_NAME = \"labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class EpisodeStep:\n",
    "    obs: np.ndarray\n",
    "    act: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class HumanLabel:\n",
    "    sample1: pathlib.Path\n",
    "    sample2: pathlib.Path\n",
    "    # 1 if sample 1 is better than 2\n",
    "    # 2 if sample 2 is better than 1\n",
    "    # 0 if they are equal\n",
    "    label: tt.Optional[int]\n",
    "\n",
    "    def to_json(self, extra_id: tt.Optional[int] = None) -> dict:\n",
    "        res = {\n",
    "            \"sample1\": str(self.sample1),\n",
    "            \"sample2\": str(self.sample2),\n",
    "            \"label\": self.label,\n",
    "        }\n",
    "        if extra_id is not None:\n",
    "            res['id'] = extra_id\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: dict) -> \"HumanLabel\":\n",
    "        return HumanLabel(\n",
    "            sample1=pathlib.Path(data['sample1']),\n",
    "            sample2=pathlib.Path(data['sample2']),\n",
    "            label=int(data['label']),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Database:\n",
    "    db_root: pathlib.Path\n",
    "    paths: tt.List[pathlib.Path]\n",
    "    labels: tt.List[HumanLabel]\n",
    "\n",
    "    def shuffle_labels(self, seed: tt.Optional[int] = None):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeRecorderWrapper(gym.Wrapper):\n",
    "    def __init__(self, env: gym.Env, db_path: pathlib.Path, env_idx: int,\n",
    "                 start_prob: float = START_PROB, steps_count: int = EPISODE_STEPS):\n",
    "        \"\"\"\n",
    "        Constructs the DB episode storage wrapper.\n",
    "        :param env: environment to wrap\n",
    "        :param db_path: path to the episode DB\n",
    "        :param env_idx: index of the environment, used for storing\n",
    "        :param start_prob: probability to start the episode capture\n",
    "        :param steps_count: count of steps to capture\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self._store_path = db_path / f\"{env_idx:02d}\"\n",
    "        self._store_path.mkdir(parents=True, exist_ok=True)\n",
    "        self._start_prob = start_prob\n",
    "        self._steps_count = steps_count\n",
    "        self._is_storing = False\n",
    "        self._steps: tt.List[EpisodeStep] = []\n",
    "        self._prev_obs = None\n",
    "        self._step_idx = 0\n",
    "\n",
    "    def reset(self, *, seed: int | None = None, options: dict[str, tt.Any] | None = None) \\\n",
    "            -> tuple[WrapperObsType, dict[str, tt.Any]]:\n",
    "        self._step_idx += 1\n",
    "        res = super().reset(seed=seed, options=options)\n",
    "        if self._is_storing:\n",
    "            self._prev_obs = deepcopy(res[0])\n",
    "        return res\n",
    "\n",
    "    def step(self, action: WrapperActType) -> tuple[\n",
    "        WrapperObsType, SupportsFloat, bool, bool, dict[str, tt.Any]\n",
    "    ]:\n",
    "        self._step_idx += 1\n",
    "        obs, r, is_done, is_tr, extra = super().step(action)\n",
    "        if self._is_storing:\n",
    "            self._steps.append(EpisodeStep(self._prev_obs, int(action)))\n",
    "            self._prev_obs = deepcopy(obs)\n",
    "\n",
    "            if len(self._steps) >= self._steps_count:\n",
    "                store_segment(self._store_path, self._step_idx, self._steps)\n",
    "                self._is_storing = False\n",
    "                self._steps.clear()\n",
    "        elif random.random() <= self._start_prob:\n",
    "            # start recording\n",
    "            self._is_storing = True\n",
    "            self._prev_obs = deepcopy(obs)\n",
    "        return obs, r, is_done, is_tr, extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_segment(root_path: pathlib.Path, step_idx: int, steps: tt.List[EpisodeStep]):\n",
    "    out_path = root_path / f\"{step_idx:08d}.dat\"\n",
    "    dat = pickle.dumps(steps)\n",
    "    out_path.write_bytes(dat)\n",
    "    print(f\"Stored {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(path: pathlib.Path) -> tt.List[HumanLabel]:\n",
    "    \"\"\"\n",
    "    Load labels from the file, but keeping only the last entries with the same (source1, source2) key.\n",
    "    This is needed, as the same samples could be labelled several times.\n",
    "    :param path: path to read\n",
    "    :return: list of labels\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    if not path.exists():\n",
    "        return res\n",
    "    seen_s12 = set()\n",
    "    for l in reversed(path.read_text().splitlines()):\n",
    "        if not l.strip():\n",
    "            continue\n",
    "        d = json.loads(l)\n",
    "        hl = HumanLabel.from_json(d)\n",
    "        key = (hl.sample1, hl.sample2)\n",
    "        if key in seen_s12:\n",
    "            continue\n",
    "        seen_s12.add(key)\n",
    "        res.append(hl)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec427871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(db_path: str) -> Database:\n",
    "    db_path = pathlib.Path(db_path)\n",
    "    labels = load_labels(db_path / LABELS_FILE_NAME)\n",
    "    paths = [\n",
    "        p.relative_to(db_path)\n",
    "        for p in sorted(db_path.glob(\"*/*.dat\"))\n",
    "    ]\n",
    "    return Database(db_root=db_path, paths=paths, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a907eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_label(db: Database, count: int = 20) -> tt.List[HumanLabel]:\n",
    "    have_pairs = {\n",
    "        (label.sample1, label.sample2) for label in db.labels\n",
    "    }\n",
    "    res = []\n",
    "    while len(res) < count:\n",
    "        p1, p2 = random.sample(db.paths, 2)\n",
    "        if (p1, p2) in have_pairs:\n",
    "            continue\n",
    "        res.append(HumanLabel(sample1=p1, sample2=p2, label=None))\n",
    "        have_pairs.add((p1, p2))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_gif(path: pathlib.Path) -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Return episode's gif file (if exists). Otherwise create one.\n",
    "    :param path: path to data file\n",
    "    :return: gif path\n",
    "    \"\"\"\n",
    "    gif_path = path.with_suffix(\".gif\")\n",
    "    if gif_path.exists():\n",
    "        return gif_path\n",
    "\n",
    "    dat = path.read_bytes()\n",
    "    steps = pickle.loads(dat)\n",
    "    sh = steps[0].obs.shape\n",
    "    im = Image.new(\"RGB\", (sh[1], sh[0]), (0, 0, 0))\n",
    "    images = [\n",
    "        Image.fromarray(step.obs)\n",
    "        for step in steps\n",
    "    ]\n",
    "    im.save(gif_path, save_all=True, append_images=images,\n",
    "            duration=300, loop=0)\n",
    "    return gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_label(db: Database, label: HumanLabel):\n",
    "    labels_path = db.db_root / LABELS_FILE_NAME\n",
    "    with labels_path.open(\"a\") as fd:\n",
    "        fd.write(json.dumps(label.to_json()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_to_tensors(path: pathlib.Path, total_actions: int) -> \\\n",
    "    tt.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    dat = path.read_bytes()\n",
    "    steps = pickle.loads(dat)\n",
    "    obs = np.stack([s.obs for s in steps])\n",
    "    # put channels first for pytorch convolution\n",
    "    obs = np.moveaxis(obs, (3, ), (1, ))\n",
    "    act_idx = np.array([s.act for s in steps])\n",
    "    acts = np.eye(total_actions)[act_idx]\n",
    "    return torch.as_tensor(obs, dtype=torch.uint8), \\\n",
    "        torch.as_tensor(acts, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65226569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, input_shape: tt.Tuple[int, ...], n_actions: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 16, kernel_size=7, stride=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=5, stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(size + n_actions, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs: torch.ByteTensor, acts: torch.Tensor) -> torch.Tensor:\n",
    "        conv_out = self.conv(obs / 255)\n",
    "        comb = torch.hstack((conv_out, acts))\n",
    "        out = self.out(comb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603fec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModelWrapper(gym.Wrapper):\n",
    "    KEY_REAL_REWARD_SUM = \"real_reward_sum\"\n",
    "    KEY_REWARD_MU = \"reward_mu\"\n",
    "    KEY_REWARD_STD = \"reward_std\"\n",
    "\n",
    "    def __init__(self, env: gym.Env, model_path: pathlib.Path, dev: torch.device,\n",
    "                 reward_window: int = 100, metrics_queue: tt.Optional[queue.Queue] = None):\n",
    "        \"\"\"\n",
    "        Constructs reward model wrapper. Use given model\n",
    "        to get the reward for the observations. This reward is\n",
    "        used instead of the real environment reward.\n",
    "        :param env: environment to wrap\n",
    "        :param model_path: path to the model weights\n",
    "        :param reward_window: size of the window for reward normalisation\n",
    "        :param metrics_queue: queue to send extra metrics\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.device = dev\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete)\n",
    "        s = env.observation_space.shape\n",
    "        self.total_actions = env.action_space.n\n",
    "        self.model = RewardModel(\n",
    "            input_shape=(s[2], s[0], s[1]), n_actions=self.total_actions)\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'),\n",
    "                                              weights_only=True))\n",
    "        self.model.eval()\n",
    "        self.model.to(dev)\n",
    "        self._prev_obs = None\n",
    "        self._reward_window = collections.deque(maxlen=reward_window)\n",
    "        self._real_reward_sum = 0.0\n",
    "        self._metrics_queue = metrics_queue\n",
    "\n",
    "    def reset(self, *, seed: int | None = None, options: dict[str, tt.Any] | None = None) \\\n",
    "            -> tuple[WrapperObsType, dict[str, tt.Any]]:\n",
    "        res = super().reset(seed=seed, options=options)\n",
    "        self._prev_obs = deepcopy(res[0])\n",
    "        self._real_reward_sum = 0.0\n",
    "        return res\n",
    "\n",
    "    def step(self, action: WrapperActType) -> tuple[\n",
    "        WrapperObsType, SupportsFloat, bool, bool, dict[str, tt.Any]\n",
    "    ]:\n",
    "        obs, r, is_done, is_tr, extra = super().step(action)\n",
    "        self._real_reward_sum += r\n",
    "        p_obs = np.moveaxis(self._prev_obs, (2, ), (0, ))\n",
    "        p_obs_t = torch.as_tensor(p_obs).to(self.device)\n",
    "        p_obs_t.unsqueeze_(0)\n",
    "        act = np.eye(self.total_actions)[[action]]\n",
    "        act_t = torch.as_tensor(act, dtype=torch.float32).to(self.device)\n",
    "        new_r_t = self.model(p_obs_t, act_t)\n",
    "        new_r = float(new_r_t.item())\n",
    "\n",
    "        # track reward for normalization\n",
    "        self._reward_window.append(new_r)\n",
    "        if len(self._reward_window) == self._reward_window.maxlen:\n",
    "            mu = np.mean(self._reward_window)\n",
    "            std = np.std(self._reward_window)\n",
    "            new_r -= mu\n",
    "            new_r /= std\n",
    "            self._metrics_queue.put((self.KEY_REWARD_MU, mu))\n",
    "            self._metrics_queue.put((self.KEY_REWARD_STD, std))\n",
    "\n",
    "        if is_done or is_tr:\n",
    "            self._metrics_queue.put((self.KEY_REAL_REWARD_SUM, self._real_reward_sum))\n",
    "        self._prev_obs = deepcopy(obs)\n",
    "        return obs, new_r, is_done, is_tr, extra"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
