{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "import gymnasium as gym\n",
    "import pathlib\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5470ba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from lib import rlhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10791dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-r\", \"--reward\", required=True,\n",
    "                        help=\"Path to reward model file\")\n",
    "    parser.add_argument(\"-d\", \"--dev\", default=\"cuda\")\n",
    "    args = parser.parse_args()\n",
    "    dev = torch.device(args.dev)\n",
    "\n",
    "    e = gym.make(\"SeaquestNoFrameskip-v4\")\n",
    "    p = pathlib.Path(args.reward)\n",
    "    e = rlhf.RewardModelWrapper(e, p, dev)\n",
    "    r, _ = e.reset()\n",
    "    obs, r, is_done, is_tr, extra = e.step(0)\n",
    "    print(obs.shape)\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
