{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b774625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import ptan\n",
    "from lib import model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d839fd4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92672958",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-mt\", \"--model-tiger\", required=True,\n",
    "                        help=\"Model file to load for tiger agent\")\n",
    "    parser.add_argument(\"-md\", \"--model-deer\", required=True,\n",
    "                        help=\"Model file to load for deer agent\")\n",
    "    parser.add_argument(\"--map-size\", type=int, default=data.MAP_SIZE,\n",
    "                        help=\"Size of the map, default=\" + str(data.MAP_SIZE))\n",
    "    parser.add_argument(\"--render\", default=\"render/video.mp4\",\n",
    "                        help=\"Name of the video file to render, default=render/video.mp4\")\n",
    "    parser.add_argument(\"--walls\", type=int, default=data.COUNT_WALLS,\n",
    "                        help=\"Count of walls, default=\" + str(data.COUNT_WALLS))\n",
    "    parser.add_argument(\"--tigers\", type=int, default=data.COUNT_TIGERS,\n",
    "                        help=\"Count of tigers, default=\" + str(data.COUNT_TIGERS))\n",
    "    parser.add_argument(\"--deer\", type=int, default=data.COUNT_DEER,\n",
    "                        help=\"Count of deer, default=\" + str(data.COUNT_DEER))\n",
    "    parser.add_argument(\"--mode\", default='forest', choices=['forest', 'double_attack'],\n",
    "                        help=\"GridWorld mode, could be 'forest' or 'double_attack', default='forest'\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.mode == 'forest':\n",
    "        env = data.ForestEnv(\n",
    "            map_size=args.map_size,\n",
    "            count_walls=args.walls,\n",
    "            count_tigers=args.tigers,\n",
    "            count_deer=args.deer,\n",
    "            render_mode=\"rgb_array\",\n",
    "        )\n",
    "    elif args.mode == 'double_attack':\n",
    "        env = data.DoubleAttackEnv(\n",
    "            map_size=args.map_size,\n",
    "            count_walls=args.walls,\n",
    "            count_tigers=args.tigers,\n",
    "            count_deer=args.deer,\n",
    "            render_mode=\"rgb_array\",\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "    recorder = VideoRecorder(env, args.render)\n",
    "    tiger_net = model.DQNModel(\n",
    "        env.observation_spaces['tiger_0'].shape,\n",
    "        env.action_spaces['tiger_0'].n,\n",
    "    )\n",
    "    tiger_net.load_state_dict(torch.load(args.model_tiger, map_location=torch.device('cpu'), weights_only=True))\n",
    "    tiger_agent = ptan.agent.DQNAgent(\n",
    "        tiger_net, ptan.actions.ArgmaxActionSelector())\n",
    "\n",
    "    deer_net = model.DQNModel(\n",
    "        env.observation_spaces['deer_0'].shape,\n",
    "        env.action_spaces['deer_0'].n,\n",
    "    )\n",
    "    deer_net.load_state_dict(torch.load(args.model_deer, map_location=torch.device('cpu'), weights_only=True))\n",
    "    deer_agent = ptan.agent.DQNAgent(\n",
    "        deer_net, ptan.actions.ArgmaxActionSelector())\n",
    "\n",
    "    obs = env.reset()\n",
    "    recorder.capture_frame()\n",
    "    total_tiger_reward = 0.0\n",
    "    total_deer_reward = 0.0\n",
    "    total_steps = 0\n",
    "\n",
    "    while env.agents:\n",
    "        actions = {}\n",
    "        tiger_obs = [\n",
    "            obs[agent_id]\n",
    "            for agent_id in env.agents\n",
    "            if agent_id.startswith(\"tiger\")\n",
    "        ]\n",
    "        tiger_acts, _ = tiger_agent(tiger_obs)\n",
    "        ofs = 0\n",
    "        for agent_id in env.agents:\n",
    "            if agent_id.startswith(\"tiger\"):\n",
    "                actions[agent_id] = tiger_acts[ofs]\n",
    "                ofs += 1\n",
    "\n",
    "        deer_obs = [\n",
    "            obs[agent_id]\n",
    "            for agent_id in env.agents\n",
    "            if agent_id.startswith(\"deer\")\n",
    "        ]\n",
    "        deer_acts, _ = deer_agent(deer_obs)\n",
    "        ofs = 0\n",
    "        for agent_id in env.agents:\n",
    "            if agent_id.startswith(\"deer\"):\n",
    "                actions[agent_id] = deer_acts[ofs]\n",
    "                ofs += 1\n",
    "\n",
    "        obs, rewards, dones, _, _ = env.step(actions)\n",
    "        recorder.capture_frame()\n",
    "        total_steps += 1\n",
    "        for agent_id, reward in rewards.items():\n",
    "            if agent_id.startswith(\"tiger\"):\n",
    "                total_tiger_reward += reward\n",
    "            if agent_id.startswith(\"deer\"):\n",
    "                total_deer_reward += reward\n",
    "\n",
    "    print(\"Episode steps: %d\" % total_steps)\n",
    "    print(\"Total tiger reward: %.3f\" % total_tiger_reward)\n",
    "    print(\"Mean tiger reward: %.3f\" % (total_tiger_reward / args.tigers))\n",
    "    print(\"Total deer reward: %.3f\" % total_deer_reward)\n",
    "    print(\"Mean deer reward: %.3f\" % (total_deer_reward / args.deer))\n",
    "    recorder.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
