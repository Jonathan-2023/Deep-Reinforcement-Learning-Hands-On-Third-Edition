{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac021832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptan\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "HID_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelActor(nn.Module):\n",
    "    def __init__(self, obs_size: int, act_size: int):\n",
    "        super(ModelActor, self).__init__()\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, act_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.logstd = nn.Parameter(torch.zeros(act_size))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863254d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCritic(nn.Module):\n",
    "    def __init__(self, obs_size: int):\n",
    "        super(ModelCritic, self).__init__()\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSACTwinQ(nn.Module):\n",
    "    def __init__(self, obs_size, act_size):\n",
    "        super(ModelSACTwinQ, self).__init__()\n",
    "\n",
    "        self.q1 = nn.Sequential(\n",
    "            nn.Linear(obs_size + act_size, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, 1),\n",
    "        )\n",
    "\n",
    "        self.q2 = nn.Sequential(\n",
    "            nn.Linear(obs_size + act_size, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=1)\n",
    "        return self.q1(x), self.q2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64414e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentA2C(ptan.agent.BaseAgent):\n",
    "    def __init__(self, net, device: torch.device):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, states: ptan.agent.States, agent_states: ptan.agent.AgentStates):\n",
    "        states_v = ptan.agent.float32_preprocessor(states)\n",
    "        states_v = states_v.to(self.device)\n",
    "\n",
    "        mu_v = self.net(states_v)\n",
    "        mu = mu_v.data.cpu().numpy()\n",
    "        logstd = self.net.logstd.data.cpu().numpy()\n",
    "        rnd = np.random.normal(size=logstd.shape)\n",
    "        actions = mu + np.exp(logstd) * rnd\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "        return actions, agent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDDPG(ptan.agent.BaseAgent):\n",
    "    \"\"\"\n",
    "    Agent implementing Orstein-Uhlenbeck exploration process\n",
    "    \"\"\"\n",
    "    def __init__(self, net, device=\"cpu\", ou_enabled=True,\n",
    "                 ou_mu=0.0, ou_teta=0.15, ou_sigma=0.2,\n",
    "                 ou_epsilon=1.0):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.ou_enabled = ou_enabled\n",
    "        self.ou_mu = ou_mu\n",
    "        self.ou_teta = ou_teta\n",
    "        self.ou_sigma = ou_sigma\n",
    "        self.ou_epsilon = ou_epsilon\n",
    "\n",
    "    def initial_state(self):\n",
    "        return None\n",
    "\n",
    "    def __call__(self, states, agent_states):\n",
    "        states_v = ptan.agent.float32_preprocessor(states)\n",
    "        states_v = states_v.to(self.device)\n",
    "        mu_v = self.net(states_v)\n",
    "        actions = mu_v.data.cpu().numpy()\n",
    "\n",
    "        if self.ou_enabled and self.ou_epsilon > 0:\n",
    "            new_a_states = []\n",
    "            for a_state, action in zip(agent_states, actions):\n",
    "                if a_state is None:\n",
    "                    a_state = np.zeros(\n",
    "                        shape=action.shape, dtype=np.float32)\n",
    "                a_state += self.ou_teta * (self.ou_mu - a_state)\n",
    "                a_state += self.ou_sigma * np.random.normal(\n",
    "                    size=action.shape)\n",
    "\n",
    "                action += self.ou_epsilon * a_state\n",
    "                new_a_states.append(a_state)\n",
    "        else:\n",
    "            new_a_states = agent_states\n",
    "\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "        return actions, new_a_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba65510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78673977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(\n",
    "        net: ModelActor, env: gym.Env, count: int = 10,\n",
    "        device: torch.device = torch.device(\"cpu\")\n",
    "):\n",
    "    rewards = 0.0\n",
    "    steps = 0\n",
    "    for _ in range(count):\n",
    "        obs, _ = env.reset()\n",
    "        while True:\n",
    "            obs_v = ptan.agent.float32_preprocessor([obs])\n",
    "            obs_v = obs_v.to(device)\n",
    "            mu_v = net(obs_v)[0]\n",
    "            action = mu_v.squeeze(dim=0).data.cpu().numpy()\n",
    "            action = np.clip(action, -1, 1)\n",
    "            obs, reward, done, is_tr, _ = env.step(action)\n",
    "            rewards += reward\n",
    "            steps += 1\n",
    "            if done or is_tr:\n",
    "                break\n",
    "    return rewards / count, steps / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf52563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logprob(mu_v: torch.Tensor, logstd_v: torch.Tensor, actions_v: torch.Tensor):\n",
    "    p1 = - ((mu_v - actions_v) ** 2) / (2*torch.exp(logstd_v).clamp(min=1e-3))\n",
    "    p2 = - torch.log(torch.sqrt(2 * math.pi * torch.exp(logstd_v)))\n",
    "    return p1 + p2"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
