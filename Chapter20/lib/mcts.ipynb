{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cce786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Monte-Carlo Tree Search\n",
    "\"\"\"\n",
    "import typing as tt\n",
    "import math as m\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import game, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b597e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    \"\"\"\n",
    "    Class keeps statistics for every state encountered during the search\n",
    "    \"\"\"\n",
    "    def __init__(self, c_puct: float = 1.0):\n",
    "        self.c_puct = c_puct\n",
    "        # count of visits, state_int -> [N(s, a)]\n",
    "        self.visit_count: tt.Dict[int, tt.List[int]] = {}\n",
    "        # total value of the state's act, state_int -> [W(s, a)]\n",
    "        self.value: tt.Dict[int, tt.List[float]] = {}\n",
    "        # average value of actions, state_int -> [Q(s, a)]\n",
    "        self.value_avg: tt.Dict[int, tt.List[float]] = {}\n",
    "        # prior probability of actions, state_int -> [P(s,a)]\n",
    "        self.probs: tt.Dict[int, tt.List[float]] = {}\n",
    "\n",
    "    def clear(self):\n",
    "        self.visit_count.clear()\n",
    "        self.value.clear()\n",
    "        self.value_avg.clear()\n",
    "        self.probs.clear()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.value)\n",
    "\n",
    "    def find_leaf(self, state_int: int, player: int):\n",
    "        \"\"\"\n",
    "        Traverse the tree until the end of game or leaf node\n",
    "        :param state_int: root node state\n",
    "        :param player: player to move\n",
    "        :return: tuple of (value, leaf_state, player, states, actions)\n",
    "        1. value: None if leaf node, otherwise equals to the game outcome for the player at leaf\n",
    "        2. leaf_state: state_int of the last state\n",
    "        3. player: player at the leaf node\n",
    "        4. states: list of states traversed\n",
    "        5. list of actions taken\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        actions = []\n",
    "        cur_state = state_int\n",
    "        cur_player = player\n",
    "        value = None\n",
    "\n",
    "        while not self.is_leaf(cur_state):\n",
    "            states.append(cur_state)\n",
    "\n",
    "            counts = self.visit_count[cur_state]\n",
    "            total_sqrt = m.sqrt(sum(counts))\n",
    "            probs = self.probs[cur_state]\n",
    "            values_avg = self.value_avg[cur_state]\n",
    "\n",
    "            # choose action to take, in the root node add the Dirichlet noise to the probs\n",
    "            if cur_state == state_int:\n",
    "                noises = np.random.dirichlet([0.03] * game.GAME_COLS)\n",
    "                probs = [0.75 * prob + 0.25 * noise for prob, noise in zip(probs, noises)]\n",
    "            score = [\n",
    "                value + self.c_puct*prob*total_sqrt/(1+count)\n",
    "                for value, prob, count in zip(values_avg, probs, counts)\n",
    "            ]\n",
    "            invalid_actions = set(range(game.GAME_COLS)) - \\\n",
    "                              set(game.possible_moves(cur_state))\n",
    "            for invalid in invalid_actions:\n",
    "                score[invalid] = -np.inf\n",
    "            action = int(np.argmax(score))\n",
    "            actions.append(action)\n",
    "            cur_state, won = game.move(cur_state, action, cur_player)\n",
    "            if won:\n",
    "                # if somebody won the game, the value of the final state is -1 (as it is on opponent's turn)\n",
    "                value = -1.0\n",
    "            cur_player = 1-cur_player\n",
    "            # check for the draw\n",
    "            moves_count = len(game.possible_moves(cur_state))\n",
    "            if value is None and moves_count == 0:\n",
    "                value = 0.0\n",
    "\n",
    "        return value, cur_state, cur_player, states, actions\n",
    "\n",
    "    def is_leaf(self, state_int):\n",
    "        return state_int not in self.probs\n",
    "\n",
    "    def search_batch(self, count, batch_size, state_int, player, net, device=\"cpu\"):\n",
    "        for _ in range(count):\n",
    "            self.search_minibatch(batch_size, state_int, player, net, device)\n",
    "\n",
    "    def search_minibatch(self, count, state_int, player, net, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Perform several MCTS searches.\n",
    "        \"\"\"\n",
    "        backup_queue = []\n",
    "        expand_states = []\n",
    "        expand_players = []\n",
    "        expand_queue = []\n",
    "        planned = set()\n",
    "        for _ in range(count):\n",
    "            value, leaf_state, leaf_player, states, actions = \\\n",
    "                self.find_leaf(state_int, player)\n",
    "            if value is not None:\n",
    "                backup_queue.append((value, states, actions))\n",
    "            else:\n",
    "                if leaf_state not in planned:\n",
    "                    planned.add(leaf_state)\n",
    "                    leaf_state_lists = game.decode_binary(leaf_state)\n",
    "                    expand_states.append(leaf_state_lists)\n",
    "                    expand_players.append(leaf_player)\n",
    "                    expand_queue.append((leaf_state, states, actions))\n",
    "\n",
    "        # do expansion of nodes\n",
    "        if expand_queue:\n",
    "            batch_v = model.state_lists_to_batch(expand_states, expand_players, device)\n",
    "            logits_v, values_v = net(batch_v)\n",
    "            probs_v = F.softmax(logits_v, dim=1)\n",
    "            values = values_v.data.cpu().numpy()[:, 0]\n",
    "            probs = probs_v.data.cpu().numpy()\n",
    "\n",
    "            # create the nodes\n",
    "            for (leaf_state, states, actions), value, prob in \\\n",
    "                    zip(expand_queue, values, probs):\n",
    "                self.visit_count[leaf_state] = [0]*game.GAME_COLS\n",
    "                self.value[leaf_state] = [0.0]*game.GAME_COLS\n",
    "                self.value_avg[leaf_state] = [0.0]*game.GAME_COLS\n",
    "                self.probs[leaf_state] = prob\n",
    "                backup_queue.append((value, states, actions))\n",
    "\n",
    "        # perform backup of the searches\n",
    "        for value, states, actions in backup_queue:\n",
    "            # leaf state is not stored in states and actions, so the value of the leaf will be the value of the opponent\n",
    "            cur_value = -value\n",
    "            for state_int, action in zip(states[::-1], actions[::-1]):\n",
    "                self.visit_count[state_int][action] += 1\n",
    "                self.value[state_int][action] += cur_value\n",
    "                self.value_avg[state_int][action] = self.value[state_int][action] / \\\n",
    "                                                    self.visit_count[state_int][action]\n",
    "                cur_value = -cur_value\n",
    "\n",
    "    def get_policy_value(self, state_int, tau=1):\n",
    "        \"\"\"\n",
    "        Extract policy and action-values by the state\n",
    "        :param state_int: state of the board\n",
    "        :return: (probs, values)\n",
    "        \"\"\"\n",
    "        counts = self.visit_count[state_int]\n",
    "        if tau == 0:\n",
    "            probs = [0.0] * game.GAME_COLS\n",
    "            probs[np.argmax(counts)] = 1.0\n",
    "        else:\n",
    "            counts = [count ** (1.0 / tau) for count in counts]\n",
    "            total = sum(counts)\n",
    "            probs = [count / total for count in counts]\n",
    "        values = self.value_avg[state_int]\n",
    "        return probs, values"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
