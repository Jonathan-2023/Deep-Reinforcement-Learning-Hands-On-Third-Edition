{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71faa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from . import cubes\n",
    "from . import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search state and method\n",
    "    \"\"\"\n",
    "    def __init__(self, cube_env, state, net, exploration_c=100, virt_loss_nu=100.0, device=\"cpu\"):\n",
    "        assert isinstance(cube_env, cubes.CubeEnv)\n",
    "        assert cube_env.is_state(state)\n",
    "\n",
    "        self.cube_env = cube_env\n",
    "        self.root_state = state\n",
    "        self.net = net\n",
    "        self.exploration_c = exploration_c\n",
    "        self.virt_loss_nu = virt_loss_nu\n",
    "        self.device = device\n",
    "\n",
    "        # Tree state\n",
    "        shape = (len(cube_env.action_enum), )\n",
    "        # correspond to N_s(a) in the paper\n",
    "        self.act_counts = collections.defaultdict(lambda: np.zeros(shape, dtype=np.uint32))\n",
    "        # correspond to W_s(a)\n",
    "        self.val_maxes = collections.defaultdict(lambda: np.zeros(shape, dtype=np.float32))\n",
    "        # correspond to P_s(a)\n",
    "        self.prob_actions = {}\n",
    "        # correspond to L_s(a)\n",
    "        self.virt_loss = collections.defaultdict(lambda: np.zeros(shape, dtype=np.float32))\n",
    "        # TODO: check speed and memory of edge-less version\n",
    "        self.edges = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edges)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"MCTS(states=%d)\" % len(self.edges)\n",
    "\n",
    "    def dump_root(self):\n",
    "        print(\"Root state:\")\n",
    "        self.dump_state(self.root_state)\n",
    "        # states, _ = cubes.explore_state(self.cube_env, self.root_state)\n",
    "        # for idx, s in enumerate(states):\n",
    "        #     print(\"\")\n",
    "        #     print(\"State %d\" % idx)\n",
    "        #     self.dump_state(s)\n",
    "\n",
    "    def dump_state(self, s):\n",
    "        print(\"\")\n",
    "        print(\"act_counts: %s\" % \", \".join(map(lambda v: \"%8d\" % v, self.act_counts[s].tolist())))\n",
    "        print(\"probs:      %s\" % \", \".join(map(lambda v: \"%.2e\" % v, self.prob_actions[s].tolist())))\n",
    "        print(\"val_maxes:  %s\" % \", \".join(map(lambda v: \"%.2e\" % v, self.val_maxes[s].tolist())))\n",
    "\n",
    "        act_counts = self.act_counts[s]\n",
    "        N_sqrt = np.sqrt(np.sum(act_counts))\n",
    "        u = self.exploration_c * N_sqrt / (act_counts + 1)\n",
    "        print(\"u:          %s\" % \", \".join(map(lambda v: \"%.2e\" % v, u.tolist())))\n",
    "        u *= self.prob_actions[s]\n",
    "        print(\"u*prob:     %s\" % \", \".join(map(lambda v: \"%.2e\" % v, u.tolist())))\n",
    "        q = self.val_maxes[s] - self.virt_loss[s]\n",
    "        print(\"q:          %s\" % \", \".join(map(lambda v: \"%.2e\" % v, q.tolist())))\n",
    "        fin = u + q\n",
    "        print(\"u*prob + q: %s\" % \", \".join(map(lambda v: \"%.2e\" % v, fin.tolist())))\n",
    "        act = np.argmax(fin, axis=0)\n",
    "        print(\"Action: %s\" % act)\n",
    "\n",
    "    def search(self):\n",
    "        s, path_actions, path_states = self._search_leaf()\n",
    "\n",
    "        child_states, child_goal = self.cube_env.explore_state(s)\n",
    "        self.edges[s] = child_states\n",
    "\n",
    "        value = self._expand_leaves([s])[0]\n",
    "        self._backup_leaf(path_states, path_actions, value)\n",
    "\n",
    "        if np.any(child_goal):\n",
    "            path_actions.append(np.argmax(child_goal))\n",
    "            return path_actions\n",
    "        return None\n",
    "\n",
    "    def _search_leaf(self):\n",
    "        \"\"\"\n",
    "        Starting the root state, find path to the leaf node\n",
    "        :return: tuple: (state, path_actions, path_states)\n",
    "        \"\"\"\n",
    "        s = self.root_state\n",
    "        path_actions = []\n",
    "        path_states = []\n",
    "\n",
    "        # walking down the tree\n",
    "        while True:\n",
    "            next_states = self.edges.get(s)\n",
    "            if next_states is None:\n",
    "                break\n",
    "\n",
    "            act_counts = self.act_counts[s]\n",
    "            N_sqrt = np.sqrt(np.sum(act_counts))\n",
    "            if N_sqrt < 1e-6:\n",
    "                act = random.randrange(len(self.cube_env.action_enum))\n",
    "            else:\n",
    "                u = self.exploration_c * N_sqrt / (act_counts + 1)\n",
    "                u *= self.prob_actions[s]\n",
    "                q = self.val_maxes[s] - self.virt_loss[s]\n",
    "                act = np.argmax(u + q)\n",
    "            self.virt_loss[s][act] += self.virt_loss_nu\n",
    "            path_actions.append(act)\n",
    "            path_states.append(s)\n",
    "            s = next_states[act]\n",
    "        return s, path_actions, path_states\n",
    "\n",
    "    def _expand_leaves(self, leaf_states):\n",
    "        \"\"\"\n",
    "        From list of states expand them using the network\n",
    "        :param leaf_states: list of states\n",
    "        :return: list of state values\n",
    "        \"\"\"\n",
    "        policies, values = self.evaluate_states(leaf_states)\n",
    "        for s, p in zip(leaf_states, policies):\n",
    "            self.prob_actions[s] = p\n",
    "        return values\n",
    "\n",
    "    def _backup_leaf(self, states, actions, value):\n",
    "        \"\"\"\n",
    "        Update tree state after reaching and expanding the leaf node\n",
    "        :param states: path of states (without final leaf state)\n",
    "        :param actions: path of actions\n",
    "        :param value: value of leaf node\n",
    "        \"\"\"\n",
    "        for path_s, path_a in zip(states, actions):\n",
    "            self.act_counts[path_s][path_a] += 1\n",
    "            w = self.val_maxes[path_s]\n",
    "            w[path_a] = max(w[path_a], value)\n",
    "            self.virt_loss[path_s][path_a] -= self.virt_loss_nu\n",
    "\n",
    "    def search_batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Perform a batches search to increase efficiency.\n",
    "        :param batch_size: size of search batch\n",
    "        :return: path to solution or None if not found\n",
    "        \"\"\"\n",
    "        batch_size = min(batch_size, len(self) + 1)\n",
    "        batch_states, batch_actions, batch_paths = [], [], []\n",
    "        for _ in range(batch_size):\n",
    "            s, path_acts, path_s = self._search_leaf()\n",
    "            batch_states.append(s)\n",
    "            batch_actions.append(path_acts)\n",
    "            batch_paths.append(path_s)\n",
    "\n",
    "        for s, path_actions in zip(batch_states, batch_actions):\n",
    "            child, goals = self.cube_env.explore_state(s)\n",
    "            self.edges[s] = child\n",
    "            if np.any(goals):\n",
    "                return path_actions + [np.argmax(goals)]\n",
    "\n",
    "        values = self._expand_leaves(batch_states)\n",
    "        for value, path_states, path_actions in zip(values, batch_paths, batch_actions):\n",
    "            self._backup_leaf(path_states, path_actions, value)\n",
    "        return None\n",
    "\n",
    "    def evaluate_states(self, states):\n",
    "        \"\"\"\n",
    "        Ask network to return policy and values\n",
    "        :param net:\n",
    "        :param states:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        enc_states = model.encode_states(self.cube_env, states)\n",
    "        enc_states_t = torch.tensor(enc_states).to(self.device)\n",
    "        policy_t, value_t = self.net(enc_states_t)\n",
    "        policy_t = F.softmax(policy_t, dim=1)\n",
    "        return policy_t.detach().cpu().numpy(), value_t.squeeze(-1).detach().cpu().numpy()\n",
    "\n",
    "    def eval_states_values(self, states):\n",
    "        enc_states = model.encode_states(self.cube_env, states)\n",
    "        enc_states_t = torch.tensor(enc_states).to(self.device)\n",
    "        value_t = self.net(enc_states_t, value_only=True)\n",
    "        return value_t.detach().cpu().numpy()\n",
    "\n",
    "    def get_depth_stats(self):\n",
    "        \"\"\"\n",
    "        Calculate minimum, maximum, and mean depth of children in the tree\n",
    "        :return: dict with stats\n",
    "        \"\"\"\n",
    "        max_depth = 0\n",
    "        sum_depth = 0\n",
    "        leaves_count = 0\n",
    "        q = collections.deque([(self.root_state, 0)])\n",
    "        met = set()\n",
    "\n",
    "        while q:\n",
    "            s, depth = q.popleft()\n",
    "            met.add(s)\n",
    "            for ss in self.edges[s]:\n",
    "                if ss not in self.edges:\n",
    "                    max_depth = max(max_depth, depth+1)\n",
    "                    sum_depth += depth+1\n",
    "                    leaves_count += 1\n",
    "                elif ss not in met:\n",
    "                    q.append((ss, depth+1))\n",
    "        return {\n",
    "            'max': max_depth,\n",
    "            'mean': sum_depth / leaves_count,\n",
    "            'leaves': leaves_count\n",
    "        }\n",
    "\n",
    "    def dump_solution(self, solution):\n",
    "        assert isinstance(solution, list)\n",
    "\n",
    "        s = self.root_state\n",
    "        r = self.cube_env.render(s)\n",
    "        print(r)\n",
    "        for aidx in solution:\n",
    "            a = self.cube_env.action_enum(aidx)\n",
    "            print(a, aidx)\n",
    "            s = self.cube_env.transform(s, a)\n",
    "            r = self.cube_env.render(s)\n",
    "            print(r)\n",
    "\n",
    "    def find_solution(self):\n",
    "        queue = collections.deque([(self.root_state, [])])\n",
    "        seen = set()\n",
    "\n",
    "        while queue:\n",
    "            s, path = queue.popleft()\n",
    "            seen.add(s)\n",
    "            c_states, c_goals = self.cube_env.explore_state(s)\n",
    "            for a_idx, (c_state, c_goal) in enumerate(zip(c_states, c_goals)):\n",
    "                p = path + [a_idx]\n",
    "                if c_goal:\n",
    "                    return p\n",
    "                if c_state in seen or c_state not in self.edges:\n",
    "                    continue\n",
    "                queue.append((c_state, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca31e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
